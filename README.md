# ğŸ“š PDF Assistant

[![Python](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Flask](https://img.shields.io/badge/flask-2.3+-green.svg)](https://flask.palletsprojects.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A modern Flask-based web application that provides intelligent PDF processing capabilities using RAG (Retrieval-Augmented Generation) technology. Upload PDFs, ask questions about their content, and get AI-powered responses with document summarization features.

## âœ¨ Features

- **ğŸ“„ PDF Upload & Processing**: Upload and process PDF documents with advanced text extraction
- **ğŸ¤– AI-Powered Querying**: Ask natural language questions about your PDF content
- **ğŸ” Vector Search**: Efficient similarity search using FAISS vector database
- **ğŸ§  RAG System**: Advanced retrieval-augmented generation for accurate responses
- **ğŸŒ Web Search Integration**: Optional web search to enhance responses with external knowledge
- **ğŸ“‹ Document Management**: View, list, delete, and summarize uploaded documents
- **ğŸ“Š Document Summarization**: Generate AI-powered summaries of your documents
- **ğŸ”— Clean API**: RESTful API endpoints for all operations
- **ğŸ’» Modern UI**: Responsive web interface with smooth animations
- **ğŸ¨ Beautiful Design**: Modern gradient UI with intuitive user experience

## ğŸ¬ Demo

### Quick Start
1. Upload a PDF document using the drag-and-drop interface
2. Ask questions about the document content
3. Generate AI-powered summaries
4. Use web search integration for enhanced responses

### Example Usage
```
ğŸ“¤ Upload: "Upload your research paper, textbook, or any PDF document"
â“ Query: "What are the main conclusions of this paper?"
ğŸ“‹ Summary: "Generate a comprehensive summary of the document"
ğŸ” Enhanced Search: "Enable web search for broader context"
```

### Screenshots
*Note: Add screenshots of your application interface here*

- Main dashboard with upload interface
- Document management and query interface  
- Summary generation and results display
- Mobile-responsive design

## ğŸ—ï¸ Architecture

```
pdf-assistant/
â”œâ”€â”€ app/                    # Flask application package
â”‚   â”œâ”€â”€ __init__.py        # Application factory
â”‚   â”œâ”€â”€ routes.py          # API routes and endpoints
â”‚   â”œâ”€â”€ static/            # CSS, JS assets
â”‚   â””â”€â”€ templates/         # Jinja2 templates
â”œâ”€â”€ utils/                 # Core utilities
â”‚   â”œâ”€â”€ pdf_parser.py      # PDF text extraction
â”‚   â”œâ”€â”€ embeddings.py      # Text embedding generation
â”‚   â”œâ”€â”€ vector_store.py    # FAISS vector database
â”‚   â”œâ”€â”€ rag.py            # RAG system implementation
â”‚   â”œâ”€â”€ llm.py            # Language model interface
â”‚   â””â”€â”€ web_search.py     # Web search integration
â”œâ”€â”€ cache/                 # Vector embeddings cache
â”œâ”€â”€ uploads/              # Uploaded PDF files
â”œâ”€â”€ tests/                # Test suite
â”œâ”€â”€ config.py             # Application configuration
â”œâ”€â”€ requirements.txt      # Python dependencies
â””â”€â”€ run.py               # Application entry point
```

## ğŸ’¡ How It Works

1. **Document Processing**: PDFs are parsed and text is extracted using advanced libraries
2. **Embeddings Generation**: Text content is converted to vector embeddings
3. **Vector Storage**: Embeddings are stored in FAISS for efficient similarity search
4. **Query Processing**: User questions are embedded and matched against document content
5. **RAG Response**: Relevant context is retrieved and used to generate accurate responses
6. **Summarization**: Documents are analyzed to create concise, informative summaries

## ğŸ› ï¸ Installation

### Prerequisites
- Python 3.8 or higher
- pip package manager

### Setup

1. **Clone the repository**:
   ```bash
   git clone <repository-url>
   cd pdf-assistant
   ```

2. **Create virtual environment**:
   ```bash
   python -m venv venv
   
   # Windows
   venv\Scripts\activate
   
   # macOS/Linux
   source venv/bin/activate
   ```

3. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

4. **Environment Configuration**:
   ```bash
   cp .env.example .env
   ```
   
   Edit `.env` file with your API keys:
   ```env
   SECRET_KEY=your-secret-key-here
   OPENAI_API_KEY=your-openai-api-key
   HUGGINGFACE_API_KEY=your-huggingface-api-key
   DEBUG=True
   ```

5. **Run the application**:
   ```bash
   python run.py
   ```

   The application will be available at `http://127.0.0.1:5000`

## ğŸ“š API Endpoints

### Document Management
- `POST /upload` - Upload and process PDF files
- `GET /documents` - List all uploaded documents
- `DELETE /document/<doc_id>` - Delete specific document

### Querying
- `POST /query` - Ask questions about document content
- `GET /summarize/<doc_id>` - Generate document summary

### Utility
- `GET /health` - Health check endpoint

## ğŸ”§ Configuration

### Environment Variables
Create a `.env` file with the following variables:

```env
# Flask Configuration
SECRET_KEY=your-secret-key-here
DEBUG=True
FLASK_ENV=development

# AI Service API Keys (choose one or more)
OPENAI_API_KEY=your-openai-api-key          # For GPT models
HUGGINGFACE_API_KEY=your-huggingface-key    # For Hugging Face models
ANTHROPIC_API_KEY=your-anthropic-key        # For Claude models

# Application Settings
MAX_CONTENT_LENGTH=16777216                  # 16MB max file size
UPLOAD_FOLDER=uploads
CACHE_FOLDER=cache
```

### Supported AI Models
- **OpenAI GPT**: GPT-3.5-turbo, GPT-4
- **Hugging Face**: Various open-source models
- **Anthropic Claude**: Claude-3, Claude-2
- **Local Models**: Sentence transformers for embeddings

## ğŸš€ Deployment

### Using Docker
```bash
# Build the image
docker build -t pdf-assistant .

# Run the container
docker run -p 5000:5000 -v $(pwd)/uploads:/app/uploads pdf-assistant
```

### Using Heroku
```bash
# Login to Heroku
heroku login

# Create app
heroku create your-app-name

# Set environment variables
heroku config:set SECRET_KEY=your-secret-key
heroku config:set OPENAI_API_KEY=your-openai-key

# Deploy
git push heroku main
```

## ğŸ“Š Performance

- **File Size Limit**: 16MB per PDF
- **Supported Formats**: PDF (text-based)
- **Response Time**: 2-5 seconds for queries
- **Concurrent Users**: Scalable with proper deployment
- **Storage**: Local file system (easily configurable for cloud storage)

## ğŸ› ï¸ Development

### Running Tests
```bash
# Run all tests
python -m pytest tests/

# Run specific test file
python test_complete_system.py

# Run with coverage
pip install pytest-cov
python -m pytest --cov=app tests/
```

### Code Structure
```
app/
â”œâ”€â”€ static/js/main.js      # Frontend JavaScript
â”œâ”€â”€ static/css/style.css   # Styling and animations
â”œâ”€â”€ templates/             # HTML templates
â””â”€â”€ routes.py             # Flask routes and API endpoints

utils/
â”œâ”€â”€ rag.py                # RAG system implementation  
â”œâ”€â”€ llm.py                # AI model integration
â”œâ”€â”€ pdf_parser.py         # PDF processing
â”œâ”€â”€ vector_store.py       # Vector database operations
â””â”€â”€ embeddings.py         # Text embedding generation
```

## ğŸ” Troubleshooting

### Common Issues

**"Module not found" errors**:
```bash
pip install -r requirements.txt
```

**PDF processing errors**:
- Ensure PDF contains extractable text
- Check file size is under 16MB
- Verify PDF is not password protected

**AI model errors**:
- Verify API keys are correctly set
- Check internet connection for API calls
- Ensure sufficient API quota/credits

**Vector store issues**:
```bash
# Clear cache and restart
rm -rf cache/embeddings/*
python run.py
```

### Getting Help
- Check the [Issues](../../issues) section
- Read the documentation in `WHERE_TO_FIND_SUMMARIES.md`
- Review test files for usage examples
